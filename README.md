# NYC Taxi Data Pipeline

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![Airflow](https://img.shields.io/badge/Airflow-2.8.1-orange.svg)](https://airflow.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5.0-red.svg)](https://spark.apache.org/)
[![dbt](https://img.shields.io/badge/dbt-1.7.4-orange.svg)](https://www.getdbt.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

An end-to-end data engineering portfolio project demonstrating modern data pipeline architecture, orchestration, and analytics using NYC Taxi & Limousine Commission trip data.

## ğŸ¯ Project Overview

This project showcases production-ready data engineering skills including:
- **Data Ingestion**: Automated download and validation of public datasets
- **Data Processing**: Distributed processing with PySpark
- **Orchestration**: Workflow management with Apache Airflow
- **Data Modeling**: Dimensional modeling with dbt
- **Data Quality**: Automated validation with Great Expectations
- **Analytics**: Interactive dashboards with Metabase
- **Infrastructure**: Containerized services with Docker

## ğŸ—ï¸ Architecture

```
NYC TLC API â†’ Ingestion â†’ Raw Data Lake (MinIO) â†’ Transformation (Spark) 
â†’ Processed Data Lake â†’ dbt Models â†’ Data Warehouse (PostgreSQL) 
â†’ Analytics (Metabase)
```

## ğŸ› ï¸ Technology Stack

| Component | Technology |
|-----------|------------|
| Orchestration | Apache Airflow |
| Processing | PySpark |
| Storage (Lake) | MinIO (S3-compatible) |
| Storage (Warehouse) | PostgreSQL |
| Transformation | dbt Core |
| Data Quality | Great Expectations |
| Visualization | Metabase |
| Containerization | Docker & Docker Compose |

## ğŸ“‹ Prerequisites

- Docker Desktop (with Docker Compose)
- 8GB RAM minimum (16GB recommended)
- 20GB free disk space
- Git

## ğŸš€ Quick Start

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd taxi-data-pipeline
   ```

2. **Initial setup**
   ```bash
   make setup
   ```

3. **Start all services**
   ```bash
   make start
   ```

4. **Access the services**
   - Airflow UI: http://localhost:8080 (username: `airflow`, password: `airflow`)
   - MinIO Console: http://localhost:9001 (username: `minioadmin`, password: `minioadmin`)
   - Metabase: http://localhost:3000

## ğŸ“ Project Structure

```
taxi-data-pipeline/
â”œâ”€â”€ airflow/              # Airflow DAGs and configuration
â”œâ”€â”€ dbt/                  # dbt models and tests
â”œâ”€â”€ spark/                # PySpark jobs
â”œâ”€â”€ ingestion/            # Data ingestion scripts
â”œâ”€â”€ great_expectations/   # Data quality expectations
â”œâ”€â”€ infra/                # Docker and init scripts
â”œâ”€â”€ tests/                # Unit and integration tests
â”œâ”€â”€ notebooks/            # Jupyter notebooks for exploration
â””â”€â”€ docs/                 # Documentation
```

## ğŸ“Š Data Model

The project implements a star schema with:
- **Fact Table**: `fact_trips`
- **Dimension Tables**: `dim_datetime`, `dim_location`, `dim_payment`, `dim_rate`
- **Aggregate Tables**: Daily summaries, hourly patterns, zone performance

## ğŸ§ª Testing

```bash
make test
```

## ğŸ“ Documentation

See the [docs](./docs) directory for detailed documentation:
- [Architecture](./docs/architecture.md)
- [Setup Guide](./docs/setup_guide.md)
- [Data Dictionary](./docs/data_dictionary.md)

## ğŸ¤ Contributing

This is a portfolio project, but suggestions are welcome! Please open an issue first to discuss proposed changes.

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- NYC Taxi & Limousine Commission for providing the data
- Open-source community for the amazing tools

---

**Built with â¤ï¸ for learning and showcasing data engineering skills**
